---
- hosts: all
  remote_user: vagrant                                           ###############
  roles:                                                         # prepare linux
  - linux                                                        ###############

- hosts: all
  remote_user: vagrant
  serial: 100%                                                    ##############
  vars:                                                           # prepare java
    jdk: "{{ java }}"                                             ##############
    file: "jdk-8u202-linux-x64.rpm"
    url: https://download.oracle.com/otn-pub/java/jdk/8u202-b08/1961070e4c9b4e26a04e7f5a083f551e/{{ file }}
    download: /vagrant/download
    etc_profiles: /etc/profile.d
  roles:
  - java

- hosts: all
  remote_user: vagrant                                          ################
  serial: 100%                                                  # prepare hadoop
  vars:                                                         ################
    version: "3.2.0"
    hadoop: hadoop-{{ version }}
    file: "{{ hadoop }}.tar.gz"
    url: http://apache.mirrors.spacedump.net/hadoop/common/{{ hadoop }}/{{ file }}
    hadoop_home: "{{ usr_local }}/{{ hadoop }}"
    hadoop_conf_dir: "{{ hadoop_home }}/etc/hadoop"
    hadoop_log_dir: "/var/log"
    download: /vagrant/download
    usr_local: /usr/local
    etc_profiles: /etc/profile.d
    system_units: /etc/systemd/system
  roles:
  - hadoop

- hosts: all
  remote_user: vagrant                                           ###############
  serial: 100%                                                   # prepare spark
  vars:                                                          ###############
    hadoop_version: "3.2.0"
    spark_version: "2.4.0"
    hadoop: hadoop-{{ hadoop_version }}
    spark: spark-{{ spark_version }}-bin-without-hadoop
    file: "{{ spark }}.tgz"
    url: http://ftp-stud.hs-esslingen.de/pub/Mirrors/ftp.apache.org/dist/spark/spark-{{ spark_version }}/{{ file }}
    hadoop_home: "{{ usr_local }}/{{ hadoop }}"
    hadoop_conf_dir: "{{ hadoop_home }}/etc/hadoop"
    hadoop_log_dir: "/var/log"
    spark_home: "{{ usr_local }}/{{ spark }}"
    spark_conf_dir: "{{ spark_home }}/conf"
    spark_log_dir: "/var/log"
    spark_worker_dir: "{{ spark_home }}/work"
    spark_events_dir: /tmp/spark-events
    download: /vagrant/download
    usr_local: /usr/local
    etc_profiles: /etc/profile.d
    system_units: /etc/systemd/system
  roles:
  - spark

- hosts: all
  remote_user: vagrant                                                  ########
  serial: 100%                                                          # reboot
  roles:                                                                ########
  - reboot
